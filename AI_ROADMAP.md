# ğŸ¤– AI Integration Roadmap for NeoTerm Terminal

## ğŸ§± Phase 1: Foundation (Core AI Engine)
- [x] Create `ai/` module with layered architecture
- [x] Design prompt system (`prompts.rs`)
- [x] Implement provider abstraction (`providers/`)
- [x] Add AI context collector (cwd, env, history)
- [x] Add configuration toggle (AI on/off, model choice)

## ğŸ’¬ Phase 2: Natural Language to Command
- [ ] Accept free-text commands from input bar
- [ ] Generate a valid shell command from prompt
- [ ] Inject terminal context (directory, file names)
- [ ] Auto-fill the command input field

## ğŸ” Phase 3: Smart Suggestions & Completion
- [ ] Suggest next likely command
- [ ] Autocomplete command as user types
- [ ] Use history and context to inform results
- [ ] Live preview below input

## ğŸ› ï¸ Phase 4: Command Fix + Error Recovery
- [ ] Detect command failure (exit code or stderr)
- [ ] Ask AI to fix or suggest corrected command
- [ ] User can 1-click apply fix

## ğŸ” Phase 5: Explain Output or Errors
- [ ] Highlight a block of output
- [ ] Click â€œExplain Outputâ€
- [ ] AI gives natural-language description

## ğŸ§  Phase 6: Agent Mode + Workflow Inference
- [ ] Turn user request into multi-step workflows
- [ ] Create & save workflows as macros
- [ ] Enable interactive agents

## ğŸ“¦ Phase 7: Provider Flexibility
- [x] Support OpenAI GPT-4o
- [ ] Support local LLMs (`ollama`, `llama.cpp`)
- [ ] Switchable in settings
- [ ] Offline fallback mode

## ğŸ” Phase 8: Privacy, Security, Rate Limiting
- [ ] Redact tokens/envs before sending prompts
- [ ] Show usage quota (if using OpenAI)
- [ ] Allow opt-out or full local-only mode
- [ ] Mask sensitive directory/file names

# ğŸ“ AI Module Directory Structure

```plaintext
src/ai/
â”œâ”€â”€ mod.rs               # Top-level module file
â”œâ”€â”€ assistant.rs         # suggest(), fix(), explain(), etc.
â”œâ”€â”€ prompts.rs           # Static + dynamic prompt builders
â”œâ”€â”€ context.rs           # Collect env, cwd, history
â”œâ”€â”€ providers/           # Abstraction over AI backends
â”‚   â”œâ”€â”€ openai.rs        # OpenAI GPT API support
â”‚   â”œâ”€â”€ ollama.rs        # Local llama.cpp/Ollama support
â”‚   â””â”€â”€ anthropic.rs     # Optional Claude API support
